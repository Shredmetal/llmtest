{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"llm_app_test","text":"<p>A semantic testing framework for LLM applications that uses LLMs to validate semantic equivalence in test outputs. </p> <p>\u2728 Test your LLM apps in minutes, not hours</p> <p>\ud83d\ude80 CI/CD ready out of the box</p> <p>\ud83d\udcb0 Cost-effective testing solution</p> <p>\ud83d\udd27 No infrastructure needed</p>"},{"location":"#due-to-the-number-of-downloads-i-am-seeing-on-pypistatsorg-i-am-including-these-instructions-in-case-a-beta-update-breaks-something-on-your-end","title":"Due to the number of downloads I am seeing on pypistats.org, I am including these instructions in case a beta update breaks something on your end:","text":""},{"location":"#emergency-rollback-instructions","title":"Emergency Rollback Instructions","text":"<p>If you experience issues with version 0.1.0b4, you can roll back to the previous stable version (0.1.0b3.post3) using one of these methods:</p>"},{"location":"#method-1-direct-installation-of-previous-version","title":"Method 1: Direct Installation of Previous Version","text":"<pre><code>pip uninstall llm-app-test \npip install llm-app-test==0.1.0b3.post3\n</code></pre>"},{"location":"#method-2-force-reinstall-if-method-1-fails","title":"Method 2: Force Reinstall (if Method 1 fails)","text":"<pre><code>pip install --force-reinstall llm-app-test==0.1.0b3.post3\n</code></pre>"},{"location":"#verification","title":"Verification","text":"<p>After rolling back, verify the installation: <pre><code>import llm_app_test \nprint(llm_app_test.version) # Should show 0.1.0b3.post3\n</code></pre></p>"},{"location":"#need-testing-ideas-check-out-the-tests-we-used-to-test-llm-app-test-here","title":"Need testing ideas? Check out the tests we used to test llm-app-test here","text":""},{"location":"#what-llm_app_test-does","title":"What llm_app_test Does","text":"<ul> <li>Tests LLM applications (not the LLMs themselves)</li> <li>Validates system message + prompt template outputs</li> <li>Ensures semantic equivalence of responses</li> <li>Tests the parts YOU control in your LLM application</li> </ul>"},{"location":"#what-llm_app_test-doesnt-do","title":"What llm_app_test Doesn't Do","text":"<ul> <li>Test LLM model performance (that's the provider's responsibility)</li> <li>Validate base model capabilities</li> <li>Test model reliability</li> <li>Handle model safety features</li> </ul>"},{"location":"#when-to-use-llm_app_test","title":"When to Use llm_app_test","text":"<ul> <li>Testing application-level LLM integration</li> <li>Validating prompt engineering</li> <li>Testing system message effectiveness</li> <li>Ensuring consistent response patterns</li> </ul>"},{"location":"#when-not-to-use-llm_app_test","title":"When Not to Use llm_app_test","text":"<ul> <li>Testing base LLM performance</li> <li>Evaluating model capabilities</li> <li>Testing model safety features</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Installation</li> <li>Quick Start</li> <li>API Reference</li> </ul>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Installation</li> <li>Quick Start</li> <li>CI/CD Integration</li> <li>Best Practices</li> <li>API Reference</li> </ul>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"#reporting-issues","title":"Reporting Issues","text":"<p>If you encounter issues: 1. Create an issue on our GitHub repository 2. Include your Python version and environment details 3. Describe the problem you encountered with version 0.1.0b4</p>"},{"location":"#support","title":"\ud83c\udd98 Support","text":"<ul> <li>Discord: Join our community</li> <li>Issues: GitHub Issues</li> <li>Documentation: Full Docs</li> <li>Email: morganj.lee01@gmail.com</li> </ul>"},{"location":"#important-note-about-rate-limits-if-running-large-numbers-of-tests","title":"\u26a0\ufe0f Important Note About Rate Limits - If Running Large Numbers of Tests:","text":""},{"location":"#anthropic-rate-limits","title":"Anthropic Rate limits:","text":"<p>Tier 1:</p> Model Maximum Requests per minute (RPM) Maximum Tokens per minute (TPM) Maximum Tokens per day (TPD) Claude 3.5 Sonnet 2024-10-22 50 40,000 1,000,000 Claude 3.5 Sonnet 2024-06-20 50 40,000 1,000,000 Claude 3 Opus 50 20,000 1,000,000 <p>Tier 2:</p> Model Maximum Requests per minute (RPM) Maximum Tokens per minute (TPM) Maximum Tokens per day (TPD) Claude 3.5 Sonnet 2024-10-22 1,000 80,000 2,500,000 Claude 3.5 Sonnet 2024-06-20 1,000 80,000 2,500,000 Claude 3 Opus 1,000 40,000 2,500,000"},{"location":"#openai-rate-limits","title":"OpenAI Rate Limits","text":"<p>Tier 1</p> Model RPM RPD TPM Batch Queue Limit gpt-4o 500 - 30,000 90,000 gpt-4o-mini 500 10,000 200,000 2,000,000 gpt-4o-realtime-preview 100 100 20,000 - gpt-4-turbo 500 - 30,000 90,000 <p>Tier 2:</p> Model RPM TPM Batch Queue Limit gpt-4o 5,000 450,000 1,350,000 gpt-4o-mini 5,000 2,000,000 20,000,000 gpt-4o-realtime-preview 200 40,000 - gpt-4-turbo 5,000 450,000 1,350,000"},{"location":"api/configuration/","title":"Configuration","text":"<p>\u2190 Back to Home</p>"},{"location":"api/configuration/#configuration","title":"Configuration","text":"<p>llm_app_test provides flexible configuration through environment variables and direct parameters.</p>"},{"location":"api/configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"api/configuration/#provider-selection","title":"Provider Selection","text":"<pre><code>LLM_PROVIDER=openai # or 'anthropic'\n</code></pre>"},{"location":"api/configuration/#api-keys","title":"API Keys","text":"<pre><code># For OpenAI (default provider)\n\nOPENAI_API_KEY=your-openai-key\n\n# For Anthropic\n\nANTHROPIC_API_KEY=your-anthropic-key\n</code></pre>"},{"location":"api/configuration/#optional-settings","title":"Optional Settings","text":"<pre><code>LLM_MODEL=gpt-4o # Model name - default for OpenAI: gpt-4o, default for anthropic: claude-3-5-sonnet-latest\nLLM_TEMPERATURE=0.0 # Response randomness (0.0-1.0) \nLLM_MAX_TOKENS=4096 # Maximum response length \nLLM_MAX_RETRIES=2 # API retry attempts\n</code></pre>"},{"location":"api/configuration/#direct-configuration","title":"Direct Configuration","text":"<p>You can also configure llm_app_test programmatically:</p> <pre><code>from llm_app_test.semanticassert.semantic_assert import SemanticAssertion\n\nasserter = SemanticAssertion(api_key=\"your-api-key\", # Strongly advised against, use env vars \n                             provider=\"openai\", # or 'anthropic' \n                             model=\"gpt-4o\", # See Supported Models \n                             temperature=0.0, # Default: 0.0 \n                             max_tokens=4096, # Default: 4096 \n                             max_retries=2 # Default: 2 \n                             )\n</code></pre>"},{"location":"api/configuration/#supported-and-recommended-models","title":"Supported (and recommended) Models","text":"<p>Model support is restricted due to the complex semantic reasoning required for accurate testing. We've found that only the most advanced models can reliably handle semantic comparison tasks.</p>"},{"location":"api/configuration/#openai","title":"OpenAI","text":"<ul> <li>gpt-4o</li> <li>gpt-4-turbo</li> </ul>"},{"location":"api/configuration/#anthropic","title":"Anthropic","text":"<ul> <li>claude-3-5-sonnet-latest</li> <li>claude-3-opus-latest (EXPENSIVE!!!)</li> </ul>"},{"location":"api/configuration/#custom-llm-configuration-advanced-users-only","title":"Custom LLM Configuration (Advanced Users Only)","text":"<p>While it's possible to inject a custom LLM using Langchain's <code>BaseLanguageModel</code>, this is strongly discouraged unless you have extensively tested your model's semantic reasoning capabilities. Smaller or less capable models will likely fail at the semantic testing tasks. If you happen to have a datacenter in your back pocket however, Llama 3.1:405B might be a good bet.</p> <pre><code># Advanced usage - Only for thoroughly tested models\nfrom llm_app_test.semanticassert.semantic_assert import SemanticAssertion\nfrom langchain_core.language_models import BaseLanguageModel\n\ncustom_llm: BaseLanguageModel = your_custom_llm\nasserter = SemanticAssertion(llm=custom_llm)\n</code></pre> <p>If you pass in a custom llm, it will disable ALL other LLM configuration options, and you have to configure that LLM yourself.</p>"},{"location":"api/configuration/#configuration-priority","title":"Configuration Priority","text":"<p>Configuration values are resolved in this order:</p> <ol> <li>Custom LLM (if provided, disables ALL other LLM settings and uses the settings of the Langchain <code>BaseLanguageModel</code> object that you have passed)</li> <li>Directly passed parameters</li> <li>Environment variables</li> <li>Default values</li> </ol> <p>Note: if a custom LLM is not passed, llm_app_test validates all configuration values at startup to prevent runtime errors.</p>"},{"location":"api/configuration/#best-practices","title":"Best Practices","text":"<ol> <li>Use environment variables for API keys</li> <li>Keep temperature at 0.0 for consistent testing</li> <li>Use default max_tokens unless you have specific needs</li> <li>Start with default max_retries (2)</li> <li>Stick with frontier models for the best results. This library is completely untested with anything other than frontier models.</li> </ol>"},{"location":"api/configuration/#navigation","title":"Navigation","text":"<ul> <li>Back to Home</li> <li>Installation Guide</li> <li>Quick Start Guide</li> <li>API Reference</li> </ul>"},{"location":"api/error-handling/","title":"Error Handling","text":"<p>\u2190 Back to Home</p>"},{"location":"api/error-handling/#error-handling","title":"Error Handling","text":"<p>llm_app_test provides specific exceptions for different error scenarios to help you handle errors gracefully in your tests.</p>"},{"location":"api/error-handling/#exception-hierarchy","title":"Exception Hierarchy","text":"<pre><code>LLMTestError # Base exception for all llm_app_test errors \n\u251c\u2500\u2500 SemanticAssertionError # When semantic matching fails \n\u251c\u2500\u2500 LLMConfigurationError # When configuration is invalid \n\u251c\u2500\u2500 LLMConnectionError # When LLM service fails \n\u2514\u2500\u2500 InvalidPromptError # When prompt construction fails - not currently in use, code left in situ for future development\n</code></pre>"},{"location":"api/error-handling/#exception-details","title":"Exception Details","text":""},{"location":"api/error-handling/#semanticassertionerror","title":"SemanticAssertionError","text":"<p>Raised when the semantic assertion fails:</p> <pre><code>try: \n    semantic_assert.assert_semantic_match(actual=\"Hello Bob\", \n                                          expected_behavior=\"A greeting for Alice\") \nexcept SemanticAssertionError as e: \n    print(f\"Test failed: {e}\") # Includes detailed reason why outputs don't match\n</code></pre>"},{"location":"api/error-handling/#llmconfigurationerror","title":"LLMConfigurationError","text":"<p>Raised when configuration is invalid:</p> <pre><code>try: \n    semantic_assert = SemanticAssertion(provider=\"invalid_provider\") \nexcept LLMConfigurationError as e: \n    print(f\"Configuration error: {e}\") # Details about invalid configuration\n</code></pre>"},{"location":"api/error-handling/#llmconnectionerror","title":"LLMConnectionError","text":"<p>Raised when LLM service fails:</p> <pre><code>try: \n    semantic_assert.assert_semantic_match(...) \nexcept LLMConnectionError as e: \n    print(f\"Service error: {e}\") # Contains original provider error details\n</code></pre>"},{"location":"api/error-handling/#invalidprompterror-not-currently-in-use","title":"InvalidPromptError (NOT CURRENTLY IN USE)","text":"<p>Raised when prompt construction fails:</p> <pre><code>try: semantic_assert.assert_semantic_match(actual=None, # Invalid input \n                                            expected_behavior=\"Some behavior\") \nexcept InvalidPromptError as e: \n    print(f\"Prompt error: {e}\")\n</code></pre>"},{"location":"api/error-handling/#error-information","title":"Error Information","text":"<p>All exceptions should provide: - Clear error message - Detailed reason (when available) - Additional context in details dictionary</p> <p>Example:</p> <pre><code>try: \n    semantic_assert.assert_semantic_match(...) \nexcept LLMTestError as e: \n    print(f\"Message: {e.message}\") print(f\"Reason: {e.reason}\") print(f\"Details: {e.details}\")\n</code></pre>"},{"location":"api/error-handling/#best-practices","title":"Best Practices","text":"<ol> <li>Always catch specific exceptions rather than the base LLMTestError</li> <li>Log the full error information for debugging</li> <li>Handle LLMConnectionError for retry logic</li> <li>Use error details for test reporting</li> </ol> <p>Note: All exceptions properly chain to their root cause, preserving the full error context.</p>"},{"location":"api/error-handling/#navigation","title":"Navigation","text":"<ul> <li>Back to Home</li> <li>Installation Guide</li> <li>Quick Start Guide</li> <li>API Reference</li> </ul>"},{"location":"api/semantic-assertion/","title":"SemanticAssertion","text":"<p>\u2190 Back to Home</p>"},{"location":"api/semantic-assertion/#semanticassertion","title":"SemanticAssertion","text":"<p>Core class for semantic testing of LLM applications.</p>"},{"location":"api/semantic-assertion/#constructor","title":"Constructor","text":"<pre><code>SemanticAssertion(api_key: Optional[str] = None, \n                  llm: Optional[BaseLanguageModel] = None, \n                  provider: Optional[Union[str, LLMProvider]] = None, \n                  model: Optional[str] = None, \n                  temperature: Optional[float] = None, \n                  max_tokens: Optional[int] = None, \n                  max_retries: Optional[int] = None )\n</code></pre>"},{"location":"api/semantic-assertion/#parameters","title":"Parameters","text":"<p>All parameters are optional (except for API key) and will use environment variables or defaults if not specified:</p> <ul> <li> <p>api_key: API key for the LLM provider</p> <ul> <li>Environment: <code>OPENAI_API_KEY</code> or <code>ANTHROPIC_API_KEY</code></li> <li>Default: None (must be provided via environment or parameter)</li> <li>If using default provider: use <code>OPENAI_API_KEY</code> since default provider is <code>openai</code></li> </ul> </li> <li> <p>llm: Pre-configured LLM instance (must be of type <code>langchain_core.language_models import BaseLanguageModel</code>)</p> <ul> <li>Default: None (if provided, bypasses all other configuration)</li> </ul> </li> <li> <p>provider: LLM provider ('openai' or 'anthropic')</p> <ul> <li>Environment: <code>LLM_PROVIDER</code></li> <li>Default: 'openai'</li> </ul> </li> <li> <p>model: Model name to use</p> </li> <li> <p>Environment: <code>LLM_MODEL</code></p> <ul> <li>Default: 'gpt-4o' for OpenAI, 'claude-3-5-sonnet-latest' for Anthropic</li> </ul> </li> <li> <p>temperature: Temperature setting for LLM responses</p> </li> <li> <p>Environment: <code>LLM_TEMPERATURE</code></p> <ul> <li>Default: 0.0</li> <li>Range: 0.0 to 1.0</li> </ul> </li> <li> <p>max_tokens: Maximum tokens for response</p> </li> <li> <p>Environment: <code>LLM_MAX_TOKENS</code></p> <ul> <li>Default: 4096</li> </ul> </li> <li> <p>max_retries: Maximum number of API call retries</p> </li> <li>Environment: <code>LLM_MAX_RETRIES</code><ul> <li>Default: 2</li> </ul> </li> </ul>"},{"location":"api/semantic-assertion/#methods","title":"Methods","text":""},{"location":"api/semantic-assertion/#assert_semantic_match","title":"assert_semantic_match","text":"<pre><code>def assert_semantic_match(actual: str, expected_behavior: str ) -&gt; None\n</code></pre> <p>Asserts that actual output semantically matches expected behavior.</p>"},{"location":"api/semantic-assertion/#parameters_1","title":"Parameters","text":"<ul> <li>actual: The actual output to test</li> <li>expected_behavior: Natural language description of expected behavior</li> </ul>"},{"location":"api/semantic-assertion/#raises","title":"Raises","text":"<ul> <li>SemanticAssertionError: If outputs don't match semantically</li> <li>LLMConnectionError: If LLM service fails</li> <li>LLMConfigurationError: If configuration is invalid</li> <li>TypeError: If inputs are None</li> </ul>"},{"location":"api/semantic-assertion/#examples","title":"Examples","text":""},{"location":"api/semantic-assertion/#basic-usage","title":"Basic Usage","text":"<pre><code>asserter = SemanticAssertion() # Uses environment variables \nasserter.assert_semantic_match(actual=\"Hello Alice, how are you?\", # In practice, use the output from your LLM application\n                               expected_behavior=\"A greeting addressing Alice\" \n                               )\n</code></pre>"},{"location":"api/semantic-assertion/#custom-configuration","title":"Custom Configuration","text":"<pre><code>asserter = SemanticAssertion(provider=\"anthropic\", \n                             model=\"claude-3-5-sonnet-latest\", # Look I can't stop you from burning a hole in your wallet but please don't use Claude 3 Opus. \n                             temperature=0.1 )\n</code></pre>"},{"location":"api/semantic-assertion/#navigation","title":"Navigation","text":"<ul> <li>Back to Home</li> <li>Installation Guide</li> <li>Quick Start Guide</li> <li>Configuration Reference</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>\u2190 Back to Home</p>"},{"location":"getting-started/installation/#installation","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10 or higher</li> <li>pip (package installer for Python)</li> </ul>"},{"location":"getting-started/installation/#installing-llm_app_test","title":"Installing llm_app_test","text":"<p>Install directly from GitHub:</p> <pre><code>pip install llm-app-test\n</code></pre>"},{"location":"getting-started/installation/#development-installation","title":"Development Installation","text":"<p>If you want to contribute to llm_app_test, install with development dependencies:</p> <pre><code># Clone the repository\n\ngit clone https://github.com/Shredmetal/llmtest.git\n\n# Change to project directory\n\ncd llm_app_test\n\n# Install with development dependencies\n\npip install -e \".[dev]\"\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Guide - Learn how to use llm_app_test</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>\u2190 Back to Home</p>"},{"location":"getting-started/quickstart/#quick-start","title":"Quick Start","text":"<p>Get up and running with llm_app_test in under 5 minutes.</p>"},{"location":"getting-started/quickstart/#1-set-up-environment","title":"1. Set Up Environment","text":"<p>Create a <code>.env</code> file in your project root:</p> <pre><code># For OpenAI\n\nOPENAI_API_KEY=your-openai-api-key-here\n\n# OR for Anthropic\n\nANTHROPIC_API_KEY=your-anthropic-key-here\n</code></pre>"},{"location":"getting-started/quickstart/#2-write-your-first-test","title":"2. Write Your First Test","text":"<pre><code>from llm_app_test.semanticassert.semantic_assert import SemanticAssertion\n\ndef my_first_semantic_test(): \n\n    # Initialize asserter \n    semantic_assert = SemanticAssertion()\n\n    # Your LLM output\n    actual_output = \"The sky is blue\"\n\n    # Expected behavior in natural language\n    expected_behavior = \"A statement about the color of the sky\"\n\n    # Test semantic equivalence\n    semantic_assert.assert_semantic_match(\n        actual=actual_output,\n        expected_behavior=expected_behavior\n)\n</code></pre>"},{"location":"getting-started/quickstart/#3-run-your-test","title":"3. Run Your Test","text":"<pre><code>pytest my_first_semantic_test.py\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>CI/CD Integration - Set up automated testing</li> <li>Configuration - Configure llm_app_test for your needs</li> </ul>"},{"location":"getting-started/quickstart/#additional-notes","title":"Additional notes:","text":""},{"location":"getting-started/quickstart/#real-world-example","title":"Real World Example","text":"<p>Want to see llm_app_test in action? Here's a real test from our test suite:</p> <pre><code>from llm_app_test.semanticassert.semantic_assert import SemanticAssertion \nfrom llm_app_test.tests.test_content_generators.test_greeting_bot import SimpleGreetingBot\n\ndef test_greeting_semantic(): \n\n    semantic_assert = SemanticAssertion()\n\n    bot = SimpleGreetingBot()\n    actual_output = bot.generate_greeting(\"Alice\")\n\n    expected_behavior = \"\"\"\n    A polite greeting that:\n    1. Addresses the person by name (Alice)\n    2. Asks about their wellbeing\n    \"\"\"\n\n    semantic_assert.assert_semantic_match(\n        actual=actual_output,\n        expected_behavior=expected_behavior\n    )\n</code></pre> <p>You can find this example in our repository: test_greeting.py</p> <p>It can be run from this project root with the following command:</p> <pre><code>pytest tests/actual_usage_tests/test_greeting.py\n</code></pre> <p>You can find and run this example:</p> <pre><code># Clone the repository\n\ngit clone https://github.com/Shredmetal/llmtest.git\n\n# Run the test\n\npytest tests/actual_usage_tests/test_greeting.py\n</code></pre>"},{"location":"guides/best-practices/","title":"Best Practices","text":"<p>\u2190 Back to Home</p>"},{"location":"guides/best-practices/#best-practices","title":"Best Practices","text":"<p>Guidelines for effective semantic testing with llm_app_test.</p>"},{"location":"guides/best-practices/#understanding-semantic-testing","title":"Understanding Semantic Testing","text":"<p>Semantic testing focuses on meaning rather than exact matches. For example:</p> <pre><code># THESE ARE SEMANTICALLY EQUIVALENT\n\nactual_1 = \"Hello Alice, how are you today?\" \nactual_2 = \"Hi Alice! Hope you're doing well!\" \nexpected = \"A polite greeting addressing Alice\"\n</code></pre>"},{"location":"guides/best-practices/#writing-good-expected-behaviors","title":"Writing Good Expected Behaviors","text":"<ol> <li>Be Specific:</li> </ol> <pre><code># Good\n\nexpected_behavior = \"\"\" A polite greeting that:\n                    Addresses the person by name (Alice)\n                    Asks about their wellbeing \"\"\"\n\n# Bad - too vague\n\nexpected_behavior = \"A nice greeting\"\n</code></pre> <ol> <li>Focus on Requirements:</li> </ol> <pre><code># Good\n\nexpected_behavior = \"\"\" An error message that:\n                    Explains the API key is invalid\n                    Provides steps to fix the issue \"\"\"\n\n# Bad - testing exact wording - DO NOT USE llm_app_test FOR THIS, JUST USE REGULAR PYTEST\n\nexpected_behavior = \"Should say 'Invalid API key'\"\n</code></pre>"},{"location":"guides/best-practices/#when-to-use-semantic-testing","title":"When to Use Semantic Testing","text":"<p>Good Use Cases: - Testing LLM outputs - Validating natural language responses - Testing content generation</p> <p>Not Suitable For: - Exact string matching - Numerical comparisons - Binary conditions</p>"},{"location":"guides/best-practices/#test-structure","title":"Test Structure","text":"<ol> <li>Keep Tests Focused:</li> </ol> <pre><code># Good\n\ndef test_greeting_format(): \"\"\"Test greeting format only\"\"\"\n\ndef test_greeting_personalization(): \"\"\"Test name usage separately\"\"\"\n\n# Bad - testing too much\n\ndef test_everything_about_greeting(): \"\"\"Testing multiple aspects at once\"\"\"\n</code></pre> <ol> <li>Clear Test Names:</li> </ol> <pre><code># Good\n\ndef test_error_message_includes_solution_steps():\n\n# Bad\n\ndef test_error():\n</code></pre>"},{"location":"guides/best-practices/#common-pitfalls","title":"Common Pitfalls","text":"<ol> <li>Over-Specific Expected Behaviors:</li> </ol> <pre><code># Too specific\n\nexpected = \"Must say hello and use exactly these words\"\n\n# Better\n\nexpected = \"Should be a greeting in conversational English\"\n</code></pre> <ol> <li>Under-Specific Expected Behaviors:</li> </ol> <pre><code># Too vague\n\nexpected = \"Should be good\"\n\n# Better\n\nexpected = \"\"\" Response should:\n           Answer the user's question\n           Use professional language\n           Stay on topic \"\"\"\n</code></pre>"},{"location":"guides/best-practices/#cost-optimization","title":"Cost Optimization","text":"<ol> <li>Use specific, focused tests</li> <li>Group related semantic tests</li> <li>Consider test importance vs cost</li> <li>Use appropriate model tiers</li> </ol>"},{"location":"guides/best-practices/#closing-words","title":"Closing words","text":"<p>In general, this is a complete different type of testing designed to mimic a human testing your LLM application.  You might need to use your brain a little bit to figure out to instruct your assistant on what to check.</p>"},{"location":"guides/best-practices/#navigation","title":"Navigation","text":"<ul> <li>Back to Home</li> <li>Installation Guide</li> <li>Quick Start Guide</li> <li>API Reference</li> </ul>"},{"location":"guides/ci-cd/","title":"CI/CD Integration","text":"<p>\u2190 Back to Home</p>"},{"location":"guides/ci-cd/#cicd-integration","title":"CI/CD Integration","text":"<p>llm_app_test is designed for seamless integration with CI/CD pipelines.</p>"},{"location":"guides/ci-cd/#setting-up-cicd","title":"Setting Up CI/CD","text":""},{"location":"guides/ci-cd/#1-environment-setup","title":"1. Environment Setup","text":"<p>Add your API keys as secrets in your CI/CD environment:</p> <pre><code># GitHub Actions example\n\nenv: OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n\n# OR\n\nenv: ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}\n</code></pre>"},{"location":"guides/ci-cd/#2-test-configuration","title":"2. Test Configuration","text":"<pre><code># tests/test_llm_app.py\n\nfrom llm_app_test.semanticassert.semantic_assert import SemanticAssertion\n\ndef test_llm_output(): \n    semantic_assert = SemanticAssertion() # Your tests here\n</code></pre>"},{"location":"guides/ci-cd/#3-cicd-pipeline-configuration","title":"3. CI/CD Pipeline Configuration","text":""},{"location":"guides/ci-cd/#github-actions-example","title":"GitHub Actions Example","text":"<pre><code>name: LLM Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Set up Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: '3.10'\n\n      - name: Install dependencies\n        run: |\n          pip install -r requirements.txt\n          pip install llm-app-test\n\n      - name: Run tests\n        env:\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        run: pytest tests/\n</code></pre>"},{"location":"guides/ci-cd/#best-practices","title":"Best Practices","text":"<ol> <li> <p>API Key Management:</p> <ul> <li>Never commit API keys</li> <li>Use CI/CD environment secrets</li> <li>Rotate keys regularly</li> </ul> </li> <li> <p>Cost Control:</p> <ul> <li>Use cheaper models in CI/CD</li> <li>Run semantic tests only on critical paths</li> <li>Consider test result caching</li> </ul> </li> <li> <p>Pipeline Optimization:</p> <ul> <li>Run traditional tests first</li> <li>Run semantic tests in parallel</li> <li>Set appropriate timeouts</li> </ul> </li> <li> <p>Error Handling:</p> <ul> <li>Implement retry logic for API failures</li> <li>Log detailed error information</li> <li>Set up alerts for repeated failures</li> </ul> </li> </ol>"},{"location":"guides/ci-cd/#common-issues","title":"Common Issues","text":"<ol> <li> <p>API Rate Limits:</p> <ul> <li>Implement exponential backoff</li> <li>Use test result caching</li> <li>Consider parallel test execution</li> </ul> </li> <li> <p>Cost Management:</p> <ul> <li>Monitor API usage</li> <li>Set budget alerts</li> <li>Use test filtering</li> </ul> </li> </ol>"},{"location":"guides/ci-cd/#navigation","title":"Navigation","text":"<ul> <li>Back to Home</li> <li>Installation Guide</li> <li>Quick Start Guide</li> <li>API Reference</li> </ul>"},{"location":"guides/testing-patterns/","title":"Testing Patterns","text":"<p>This guide demonstrates common semantic testing patterns using llm-app-test. For API reference and syntax, see API Documentation.</p>"},{"location":"guides/testing-patterns/#pattern-basic-semantic-equivalence","title":"Pattern: Basic Semantic Equivalence","text":"<p>Scenario: Testing simple greeting behaviour</p> <p>Implementation:</p> <pre><code>actual = \"Hello Alice, how are you today?\" \n\nexpected_behavior = \"\"\" A polite greeting that:\n    Addresses the person by name (Alice)\n    Asks about their wellbeing \"\"\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> <p>Result: \u2705 PASS</p> <ul> <li>Recognises personal address</li> <li>Identifies greeting context</li> <li>Validates wellbeing inquiry</li> </ul>"},{"location":"guides/testing-patterns/#pattern-basic-semantic-matching","title":"Pattern: Basic Semantic Matching","text":"<p>Scenario: Testing simple factual statements</p> <p>Implementation:</p> <p><pre><code>actual = \"The sky is blue\"\n\nexpected_behavior = \"A statement about the color of the sky\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u2705 PASS</p> <ul> <li>Shows direct semantic matching</li> <li>Clear relationship between statement and expectation</li> <li>Passes when meaning aligns</li> </ul>"},{"location":"guides/testing-patterns/#pattern-expected-semantic-mismatch","title":"Pattern: Expected Semantic Mismatch","text":"<p>Scenario: Validating semantic mismatch detection</p> <p>Implementation:</p> <p><pre><code>actual = \"The sky is blue\"\n\nexpected_behavior = \"A statement about the weather forecast\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u274c FAIL</p> <ul> <li>Fails because the actual statement is about sky colour</li> <li>Expected behaviour asks for weather forecast information</li> <li>Demonstrates how semantic mismatches are caught</li> <li>Shows when assertions will fail in your tests</li> </ul>"},{"location":"guides/testing-patterns/#pattern-multilingual-semantic-testing","title":"Pattern: Multilingual Semantic Testing","text":"<p>Scenario: Testing semantic understanding across languages</p> <p>Implementation:</p> <p><pre><code>actual = \"Bonjour, comment allez-vous?\"\n\nexpected_behavior = \"A polite greeting asking about wellbeing\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u2705 PASS</p> <ul> <li>Demonstrates language-agnostic understanding</li> <li>Shows cross-language semantic matching</li> <li>Validates international content handling</li> </ul>"},{"location":"guides/testing-patterns/#pattern-technical-documentation-testing","title":"Pattern: Technical Documentation Testing","text":"<p>Scenario: Testing technical concept explanations</p> <p>Implementation:</p> <p><pre><code>actual = \"\"\"The TCP handshake is a three-way process where the client \n         sends SYN, server responds with SYN-ACK, and client confirms with ACK\"\"\"\n\nexpected_behavior = \"An explanation of the TCP connection establishment process\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u2705 PASS</p> <ul> <li>Validates technical accuracy</li> <li>Handles specialised terminology</li> <li>Maintains semantic precision</li> </ul>"},{"location":"guides/testing-patterns/#pattern-contextual-disambiguation","title":"Pattern: Contextual Disambiguation","text":"<p>Scenario: Testing understanding of ambiguous terms</p> <p>Implementation:</p> <p><pre><code>actual = \"The bank was steep and covered in wildflowers\"\n\nexpected_behavior = \"A description of a riverbank or hillside, not a financial institution\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u2705 PASS</p> <ul> <li>Shows contextual understanding</li> <li>Handles ambiguous terms</li> <li>Validates specific meaning exclusions</li> </ul>"},{"location":"guides/testing-patterns/#pattern-sentiment-analysis","title":"Pattern: Sentiment Analysis","text":"<p>Scenario: Testing subtle emotional content</p> <p>Implementation:</p> <p><pre><code>actual = \"While the presentation wasn't perfect, it showed promise\"\n\nexpected_behavior = \"A constructive criticism with mixed but generally positive sentiment\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u2705 PASS</p> <ul> <li>Detects nuanced sentiment</li> <li>Understands mixed emotions</li> <li>Validates overall tone</li> </ul>"},{"location":"guides/testing-patterns/#pattern-long-form-content","title":"Pattern: Long-Form Content","text":"<p>Scenario: Testing comprehension of detailed explanations</p> <p>Implementation:</p> <p><pre><code>actual = \"\"\"Machine learning is a subset of artificial intelligence \n         that enables systems to learn and improve from experience without \n         explicit programming. It focuses on developing computer programs \n         that can access data and use it to learn for themselves.\"\"\"\n\nexpected_behavior = \"A comprehensive definition of machine learning emphasizing autonomous learning and data usage\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u2705 PASS</p> <ul> <li>Handles longer text</li> <li>Maintains context</li> <li>Captures key concepts</li> </ul>"},{"location":"guides/testing-patterns/#pattern-subtle-sentiment-mismatch","title":"Pattern: Subtle Sentiment Mismatch","text":"<p>Scenario: Testing detection of subtle sentiment differences</p> <p>Implementation:</p> <p><pre><code>actual = \"The project was completed on time, though there were some hiccups\"\n\nexpected_behavior = \"A statement expressing complete satisfaction with project execution\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u274c FAIL</p> <ul> <li>Fails because actual statement indicates mixed satisfaction</li> <li>Expected behaviour suggests complete satisfaction</li> <li>Shows sensitivity to subtle emotional differences</li> </ul>"},{"location":"guides/testing-patterns/#pattern-technical-context-mismatch","title":"Pattern: Technical Context Mismatch","text":"<p>Scenario: Testing technical meaning precision</p> <p>Implementation:</p> <p><pre><code>actual = \"The function returns a pointer to the memory address\"\n\nexpected_behavior = \"A description of a function that returns the value stored at a memory location\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u274c FAIL</p> <ul> <li>Fails because returning a pointer is different from returning a stored value</li> <li>Shows precision in technical context</li> <li>Validates technical accuracy</li> </ul>"},{"location":"guides/testing-patterns/#pattern-ambiguous-reference-testing","title":"Pattern: Ambiguous Reference Testing","text":"<p>Scenario: Testing handling of context-dependent terms</p> <p>Implementation:</p> <p><pre><code>actual = \"The bank processed the transaction after reviewing the account\"\n\nexpected_behavior = \"A description of a riverbank's geological formation process\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u274c FAIL</p> <ul> <li>Fails because contexts are completely different</li> <li>Shows strong contextual understanding</li> <li>Validates semantic boundaries</li> </ul>"},{"location":"guides/testing-patterns/#pattern-temporal-context","title":"Pattern: Temporal Context","text":"<p>Scenario: Testing time-based semantic understanding</p> <p>Implementation:</p> <p><pre><code>actual = \"I will have completed the task by tomorrow\"\n\nexpected_behavior = \"A statement about a task that was completed in the past\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u274c FAIL</p> <ul> <li>Fails because of tense mismatch</li> <li>Shows temporal awareness</li> <li>Validates time context</li> </ul>"},{"location":"guides/testing-patterns/#pattern-logical-implication","title":"Pattern: Logical Implication","text":"<p>Scenario: Testing logical relationship understanding</p> <p>Implementation:</p> <p><pre><code>actual = \"If it rains, the ground will be wet\"\n\nexpected_behavior = \"A statement indicating that wet ground always means it has rained\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u274c FAIL</p> <ul> <li>Fails because of reversed logical implication</li> <li>Shows logical relationship understanding</li> <li>Validates causality direction</li> </ul>"},{"location":"guides/testing-patterns/#pattern-multi-step-reasoning","title":"Pattern: Multi-Step Reasoning","text":"<p>Scenario: Testing complex logical chains</p> <p>Implementation:</p> <p><pre><code>actual = \"\"\"When water freezes, it expands by approximately 9% in volume. \nThis expansion creates less dense ice that floats according to Archimedes' principle of displacement. \nBecause Arctic sea ice is already floating in the ocean, its melting doesn't significantly affect sea levels - \nit's already displacing its weight in water. However, land-based glaciers in places like Greenland \naren't currently displacing any ocean water. When these glaciers melt, they add entirely new water volume \nto the oceans, making them a primary contributor to sea level rise.\"\"\"\n\nexpected_behavior = \"\"\"A multi-step scientific explanation.\nMust maintain logical consistency across all steps.\"\"\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u2705 PASS</p> <ul> <li>Handles complex logical chains</li> <li>Maintains consistency across steps</li> <li>Validates scientific reasoning</li> </ul>"},{"location":"guides/testing-patterns/#pattern-nonsensical-content","title":"Pattern: Nonsensical Content","text":"<p>Scenario: Testing handling of grammatically correct but meaningless content</p> <p>Implementation:</p> <p><pre><code>actual = \"The colorless green ideas sleep furiously\"\n\nexpected_behavior = \"A grammatically correct but semantically nonsensical statement\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u2705 PASS</p> <ul> <li>Recognizes grammatical structure</li> <li>Identifies semantic nonsense</li> <li>Validates meta-understanding</li> </ul>"},{"location":"guides/testing-patterns/#pattern-extended-narrative","title":"Pattern: Extended Narrative","text":"<p>Scenario: Testing long-form narrative understanding</p> <p>Implementation:</p> <p><pre><code>actual = \"\"\"\n        The Roman Empire's rise began with modest origins in central Italy. What started as a small \n        settlement along the Tiber River would eventually become one of history's most influential \n        civilizations. In the early days, Rome was ruled by kings, but this system was overthrown \n        in 509 BCE, giving birth to the Roman Republic.\n\n        During the Republic, Rome expanded its territory through military conquest and diplomatic \n        alliances. The Roman army became increasingly professional, developing innovative tactics \n        and technologies. This military success brought wealth and power, but also internal \n        challenges. Social tensions grew between patricians and plebeians, leading to significant \n        political reforms.\n\n        By the 1st century BCE, the Republic faced severe internal strife. Military commanders \n        like Marius, Sulla, and eventually Julius Caesar accumulated unprecedented power. Caesar's \n        crossing of the Rubicon in 49 BCE marked a point of no return. His assassination in 44 BCE \n        led to another civil war, ultimately resulting in his adopted heir Octavian becoming \n        Augustus, the first Roman Emperor.\n\n        Augustus transformed Rome into an empire while maintaining a facade of republican \n        institutions. He implemented sweeping reforms in administration, military organization, \n        and public works. The Pax Romana that followed brought unprecedented peace and prosperity \n        across the Mediterranean world. Trade flourished, cities grew, and Roman culture spread \n        throughout the empire.\n        \"\"\"\n\nexpected_behavior = \"\"\"A historical narrative that:\n1. Maintains chronological progression\n2. Shows cause-and-effect relationships\n3. Develops consistent themes (power, governance, military)\n4. Connects multiple historical events coherently\n5. Demonstrates character development (e.g., Caesar to Augustus)\n\"\"\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u2705 PASS</p> <ul> <li>Handles extended narratives</li> <li>Maintains thematic consistency</li> <li>Validates complex relationships</li> <li>Shows chronological understanding</li> </ul>"},{"location":"guides/testing-patterns/#pattern-emoji-quantity-testing","title":"Pattern: Emoji Quantity Testing","text":"<p>Scenario: Testing recognition of repeated emojis</p> <p>Implementation:</p> <pre><code>actual = \"\ud83e\udd16\" * 100\n\nexpected_behavior = \"A lot of emojis\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> <p>Result: \u2705 PASS</p> <ul> <li>Handles repeated Unicode characters</li> <li>Recognises quantity concepts</li> <li>Validates emoji processing</li> </ul>"},{"location":"guides/testing-patterns/#pattern-emoji-quantity-mismatch","title":"Pattern: Emoji Quantity Mismatch","text":"<p>Scenario: Testing quantity recognition accuracy</p> <p>Implementation:</p> <p><pre><code>actual = \"\ud83e\udd16\" * 100\n\nexpected_behavior = \"Only a few emojis\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u274c FAIL</p> <ul> <li>Fails due to quantity mismatch</li> <li>Shows quantity awareness</li> <li>Validates numerical understanding</li> </ul>"},{"location":"guides/testing-patterns/#pattern-mixed-unicode-content-known-reliability-issue","title":"Pattern: Mixed Unicode Content \u26a0\ufe0f Known Reliability Issue","text":"<p>Scenario: Testing complex Unicode combinations and repetitive patterns</p>"},{"location":"guides/testing-patterns/#observed-behavior","title":"Observed Behavior","text":"<p>Test Case 1: Strict Pattern Matching</p> <pre><code>actual = \"\ud83e\udd16\ud83d\udc7e\" * 50 + \"\u3053\u3093\u306b\u3061\u306f\" * 20 + \"\ud83c\udf08\" * 30\n\nexpected_behavior = \"A mix of emojis and Japanese text\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> <p>Results:</p> <ul> <li>\u2705 Success Rate: 96% (48/50 runs)</li> <li>\u274c Failure Rate: 4% (2/50 runs)</li> <li>\ud83d\udd0d Failure Analysis:<ul> <li>Occurs primarily during increased API latency</li> <li>GPT-4o occasionally interprets sequential patterns as \"distinct collections\" rather than \"mixed content\"</li> <li>Failure message example: \"This is not a mix as there is a distinct collection of emojis followed by Japanese text and then a collection of rainbows\"</li> </ul> </li> </ul>"},{"location":"guides/testing-patterns/#recommended-implementation","title":"Recommended Implementation","text":"<p>Test Case 2: Pattern-Agnostic Matching</p> <pre><code>actual = \"\ud83e\udd16\ud83d\udc7e\" * 50 + \"\u3053\u3093\u306b\u3061\u306f\" * 20 + \"\ud83c\udf08\" * 30\n\nexpected = \"More than one type of emoji and Japanese text regardless of order\"\n\nasserter.assert_semantic_match(actual, expected)\n</code></pre> <p>Results:</p> <ul> <li>\u2705 Success Rate: 100% (preliminary)</li> <li>\u26a0\ufe0f Extended testing in progress</li> <li>\ud83d\udd0d Monitoring prompt effectiveness across different test scenarios</li> </ul>"},{"location":"guides/testing-patterns/#best-practices","title":"Best Practices","text":"<ol> <li>Use pattern-agnostic assertions for repetitive Unicode content</li> <li>Consider implementing retry logic for critical tests</li> <li>Monitor API response times during failures</li> <li>Use enhanced prompts for complex Unicode pattern testing</li> </ol>"},{"location":"guides/testing-patterns/#ongoing-investigation","title":"Ongoing Investigation","text":"<ul> <li>Testing various prompt configurations to improve reliability</li> <li>Monitoring performance impact of different prompt strategies</li> <li>Collecting data on failure patterns with different prompt versions</li> </ul>"},{"location":"guides/testing-patterns/#pattern-multilingual-emoji-spam","title":"Pattern: Multilingual Emoji Spam","text":"<p>Scenario: Testing repeated multilingual content</p> <p>Implementation:</p> <p><pre><code>actual = \"Hello\u4f60\u597dBonjour\ud83c\udf08\" * 50\n\nexpected_behavior = \"A repetitive greeting in multiple languages with rainbows\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u2705 PASS</p> <ul> <li>Handles multilingual text</li> <li>Recognises repetitive patterns</li> <li>Validates mixed content types</li> </ul>"},{"location":"guides/testing-patterns/#pattern-ascii-art-recognition","title":"Pattern: ASCII Art Recognition","text":"<p>Scenario: Testing complex ASCII art patterns</p> <p>Implementation:</p> <p><pre><code>actual = \"\"\"\n(\u256f\u00b0\u25a1\u00b0)\u256f\ufe35 \u253b\u2501\u253b\n\"\"\" * 20\n\nexpected_behavior = \"Multiple instances of table-flipping ASCII art\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u2705 PASS</p> <ul> <li>Recognises ASCII art patterns</li> <li>Understands visual representations</li> <li>Validates repeated patterns</li> </ul>"},{"location":"guides/testing-patterns/#pattern-extreme-whitespace","title":"Pattern: Extreme Whitespace","text":"<p>Scenario: Testing handling of excessive spacing</p> <p>Implementation:</p> <p><pre><code>actual = \"hello    \" + \" \" * 1000 + \"    world\" + \"\\n\" * 500\n\nexpected_behavior = \"A greeting with excessive spacing\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u2705 PASS</p> <ul> <li>Handles extreme whitespace</li> <li>Maintains semantic meaning</li> <li>Validates text normalisation</li> </ul>"},{"location":"guides/testing-patterns/#pattern-number-pattern-recognition","title":"Pattern: Number Pattern Recognition","text":"<p>Scenario: Testing numerical pattern understanding</p> <p>Implementation:</p> <p><pre><code>actual = \"\".join([str(i % 10) for i in range(1000)])\n\nexpected_behavior = \"A long sequence of repeating numbers\"\n\nsemantic_assert.assert_semantic_match(actual, expected_behavior)\n</code></pre> Result: \u2705 PASS</p> <ul> <li>Recognises numerical patterns</li> <li>Handles long repetitive sequences</li> <li>Validates pattern understanding</li> </ul>"}]}